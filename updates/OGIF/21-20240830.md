---
tags:
  - office-hours
  - ogif
  - discord
title: "OGIF Office Hours #21 - Community engagement, Go weekly, Journey of thought for prompt engineering"
short_title: "#21 Community engagement, Go weekly, Journey of thought for prompt engineering"
date: 2024-09-05
description: Our latest community discussion covers key topics such as increasing community engagement, the introduction of the DFG token for contribution recognition, building an internet brand, and market trends toward AI and tech advancements. We’ll also explore small tool development for monetization and insights on reducing software development costs with new technologies. Join us to learn more about upcoming initiatives and activities.
authors:
  - innno_
---

81 minutes

### Topics & Highlights
- Increasing community engagement and knowledge sharing:
- Introduction of the DFG token and contribution recognition.
- Focus on building an internet brand and improving team collaboration.
- Market trends shifting towards AI and tech advancements.
- Encouragement for small tool development and monetization.
- Plans for future community initiatives and activities.
- Insights on software development cost reduction through new technologies.

---

**Vietnamese transcript**

**00:00** - Bắt đầu buổi họp

Ok, anh em đông đủ chưa? Thành ơi, nay muốn bắt đầu từ đâu? Anh em còn thiếu ai không? Hình như bên Thành có vấn đề với âm thanh rồi, nghe không rõ. Ok, vậy chắc là mọi người đã đủ rồi, mình bắt đầu nhé.

**11:46** - Tóm tắt hoạt động tháng 8

Chào mọi người, quay trở lại với OGIF tuần này. Hôm nay chúng ta sẽ kết hợp với một số báo cáo về hoạt động tháng 8. Về cơ bản thì không có gì quá mới mẻ, ngoại trừ việc sau 3 tháng chạy thử nghiệm cơ chế ICY, chúng ta thấy các hoạt động thảo luận về kiến thức đang gia tăng theo kế hoạch, thậm chí còn vượt mục tiêu đề ra. Đây là một tín hiệu rất tích cực, và là điều mà anh cảm thấy có giá trị nhất hiện tại.

<iframe width="560" height="315" src="https://www.youtube.com/embed/vu0jI6rm8go?si=JQcjfgv_r0KiyFhg&amp;start=792" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

**12:39** - Kết quả từ việc áp dụng ICY

Điều rõ ràng nhất mà chúng ta thấy được từ việc áp dụng ICY là cơ hội học hỏi và thảo luận mỗi thứ Sáu hàng tuần. Mọi người đều có cơ hội đưa ra các vấn đề và cùng nhau thảo luận, học hỏi từ nhau. Đó là kết quả rõ ràng nhất mà chúng ta có được từ tháng 8 này. Trong buổi họp trước, một bạn trong team có hỏi về token dfg của team mình, và hôm nay chúng ta sẽ bàn thêm về vấn đề này.

**13:21** - Giới thiệu về Token dfg

Cụ thể, trong bản kế hoạch từ đầu năm của team, chúng ta mong muốn xây dựng một "internet brand" mạnh mẽ mà ai cũng có thể tự hào là một phần của nó. Token dfg này sẽ hoạt động giống như một loại cổ phiếu, nhưng chỉ dành riêng cho nội bộ. Để có được Token này trước năm 2020, mọi người phải xem nó như một dạng eop (Employee Ownership Program) nội bộ. Hiện nay, chúng ta đang chuyển đổi cơ chế ghi nhận đóng góp và chuẩn bị cho việc earn token này thông qua các hoạt động trong team.

**14:10** - Kế hoạch phát triển Token dfg

Ban đầu, Token dfg hoạt động như một cổ phiếu riêng tư. Nhưng sau đó, chúng ta đã thông báo về việc mọi người có thể earn Token này qua các hoạt động đóng góp trong team. Trong khi team đang tiến hành các hoạt động theo kế hoạch, chúng ta cũng đang chuẩn bị để tất cả thành viên có thể earn Token này. Hiện tại, để earn được Token này, mọi người cần phải có đồng ICY và tham gia các hoạt động được liệt kê trong kênh earn ICY.

**14:51** - Token dfg và quy trình ghi nhận đóng góp

Để có được token dfg trước năm 2020, nó được coi như một loại cổ phiếu nội bộ hoặc chương trình ESOP. Tuy nhiên, hiện tại chúng ta đã thiết lập quy trình ghi nhận đóng góp cho team. Việc này giúp các thành viên có thể earn token dfg thông qua việc đóng góp vào các hoạt động của team. Bước tiếp theo là anh em cần có đồng IC để có thể tham gia các hoạt động được liệt kê trong kênh earn IC.

**15:35** - Đóng góp vào team

Mọi người có thể earn ICY bằng cách tham gia các hoạt động như research, chia sẻ kiến thức, hoặc tham gia trực tiếp vào các dự án. Những đóng góp này sẽ được ghi nhận và chuyển đổi thành ICY. Các hoạt động như rút tiền giúp người khác cũng có thể được xem là một cách để tích lũy ICY. Ngoài ra, một số thành viên cũng có thể sử dụng ICY thông qua cơ chế ứng lương.

**16:45** - Phát triển brand

Việc ghi nhận đóng góp và sở hữu token dfg sẽ giúp chúng ta xây dựng thương hiệu của team mạnh mẽ. Team đang thiết lập các cơ chế để mọi người có thể dễ dàng đóng góp và sở hữu một phần token của team. Các token này có thể được sử dụng trong các hoạt động nội bộ và có khả năng mở rộng ra bên ngoài thông qua quá trình staking. Đây là một bước quan trọng trong việc phát triển hệ thống quản trị phi tập trung (DFG).

**19:08** - Thị trường và xu hướng AI

Trong 3 tháng gần đây, chủ đề liên quan đến AI đang ngày càng được chú ý, với nhiều ứng dụng AI được giới thiệu và phát triển. Team chúng ta cũng đang chuyển dịch theo hướng này, với các hoạt động như demo AI tools, và những chủ đề liên quan đến sự dịch chuyển của thị trường công nghệ. Trong tháng 9, team sẽ công bố thêm các hướng dẫn chính thức liên quan đến việc phát triển các dự án AI nhỏ, tập trung vào việc giải quyết những vấn đề cụ thể và tối ưu hóa quy trình làm việc.

**21:13** - Ảnh hưởng của AI đến chi phí phát triển phần mềm

Chi phí để phát triển phần mềm đang ngày càng giảm nhờ sự phát triển của AI. Các công ty sẽ không còn phải đầu tư quá nhiều vào các hoạt động thủ công, mà thay vào đó là tìm kiếm những người có khả năng sử dụng AI một cách hiệu quả. Sự thay đổi này sẽ tạo ra một thế hệ doanh nhân mới, những người có thể tận dụng AI để xây dựng các sản phẩm phần mềm nhanh chóng và hiệu quả hơn. Team chúng ta cũng đang chuyển dịch theo hướng này.

**22:33** - Stream chính thức và các dự án open-source

Trong tháng 9, team sẽ triển khai các dự án open-source nhỏ, tập trung vào việc giải quyết các vấn đề cụ thể thông qua các công cụ mạnh mẽ. Những ai tham gia vào các dự án này và có thể biến chúng thành sản phẩm hoàn chỉnh sẽ được ghi nhận và thưởng IC. Đây là một hướng đi mới nhằm khuyến khích các thành viên tạo ra những sản phẩm nhỏ nhưng sắc bén, góp phần vào sự phát triển của team.

**23:57** - Tình hình tuyển dụng và layoff

Mặc dù có một số layoff trong thị trường công nghệ, nhưng nhu cầu tuyển dụng vẫn còn, đặc biệt là ở các công ty vừa và nhỏ, nơi họ đang thử nghiệm với các công nghệ mới. Nhiều công ty lớn vẫn đang tinh chỉnh lại bộ máy nhân sự của họ để thích nghi với sự dịch chuyển này. AI tiếp tục đóng vai trò quan trọng trong việc tối ưu hóa chi phí và quy trình phát triển phần mềm.

**25:41** - Tình hình vận hành của team

Một số dự án consulting đã bị tạm dừng do không còn phù hợp với thị trường, dẫn đến việc giảm bớt một số nguồn lực đầu tư. Tuy nhiên, đây là cơ hội để team chúng ta tập trung vào các dự án chiến lược hơn và xây dựng các case study giá trị. Hiện tại, hoạt động của team vẫn đang diễn ra suôn sẻ, và các dự án AI mới sẽ tiếp tục được triển khai trong thời gian tới.

**26:20** - Phần trình bày OGIF

Chúng ta có ba bài trong buổi hôm nay. Bài thứ nhất là về phần Lego và phần tiếp theo là về MC với các khía cạnh liên quan đến enterprise. Bài thứ ba là tổng kết market report, liên quan đến AI mà chúng ta đã thảo luận. Bài cuối là phần chia sẻ của Tom về quy trình xử lý một prompt bằng AI, cách tạo ra một prompt hiệu quả hơn cho quá trình xử lý thông tin.

**27:05** - Phân tích sâu về mindset khi làm developer

Hôm trước, Minh cloud đã chia sẻ phần liên quan đến việc xử lý dữ liệu từ góc nhìn của một user bình thường. Tuy nhiên, hôm nay chúng ta sẽ đi sâu hơn từ góc nhìn của một developer, đặc biệt là về mindset của các developer trong quá trình phát triển hệ thống.

**27:51** - Quang Lê và portfolio của team

Trong tuần qua, Quang Lê đã chuẩn bị một báo cáo tổng kết về portfolio của team, bao gồm việc tổng hợp thông tin từ các dự án khác nhau. Chúng ta sẽ xem qua các dự án này để có cái nhìn tổng quan về những gì đã thực hiện và những gì cần cải thiện.

**30:03** - Tổng hợp dữ liệu và xuất bản báo cáo

Trong quá trình tổng hợp, Quan đã sử dụng EOM và các công cụ khác để thu thập dữ liệu từ nhiều nguồn. Sau đó, thông tin được xuất thành các tệp PDF để dễ dàng chia sẻ và lưu trữ. Mọi thứ từ blockchain cho đến các dự án khác đều được tổng hợp lại.

**31:25** - Sử dụng AI trong việc tổng hợp báo cáo

Quan đã sử dụng các công cụ AI như GPT và Cloud để xử lý các tài liệu PDF và tạo ra một bản tóm tắt chi tiết cho từng dự án. Sau khi các tài liệu PDF được quét, AI sẽ trích xuất thông tin và tạo ra các báo cáo tổng kết dưới dạng case study.

<iframe width="560" height="315" src="https://www.youtube.com/embed/vu0jI6rm8go?si=DEn7qhrX369htqV7&amp;start=1897" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

**35:11** - Tự động hóa quy trình tạo báo cáo

Bằng cách sử dụng các công cụ như Cloud và GPT, Quan đã tự động hóa phần lớn quy trình tạo báo cáo. Điều này giúp tiết kiệm thời gian và đảm bảo rằng các thông tin được thu thập và xử lý một cách chính xác. Việc tự động hóa còn cho phép dễ dàng cập nhật thông tin khi cần thiết.

**37:31** - Trình bày case study

Các case study từ các dự án đã được xử lý bằng AI và xuất thành báo cáo hoàn chỉnh. Quá trình này giúp chúng ta dễ dàng nắm bắt được những kỹ năng đã được phát triển qua từng dự án và những bước tiếp theo cần thực hiện.

**38:13** - Quá trình xử lý dữ liệu và tổng hợp thông tin

Quan đã mất khoảng hai tuần để hoàn thành việc tổng hợp và tạo báo cáo cho hơn mười dự án. Đây là một phương pháp hữu ích để theo dõi tiến trình của team và đánh giá các kỹ năng phát triển qua các dự án khác nhau.

**39:15** - Prompt Engineering

Tom sẽ giải thích về prompt engineering và cách tạo ra các prompt để xử lý thông tin bằng AI. Trước đây, chúng ta đã làm điều này thủ công, nhưng hiện tại chúng ta sẽ sử dụng AI để tự động hóa quá trình này. Mục tiêu của bài hôm nay là tạo ra một prompt để tự động hóa quy trình xử lý dữ liệu từ hình ảnh hoặc hội thoại và trích xuất thông tin đặc biệt từ đó.

**39:49** - Prompt cho việc tạo ra một JSON

Mục tiêu của JSON này là liên quan đến OSINT (Open Source Intelligence). Tôi sẽ sử dụng một bức ảnh làm input và dùng AI để đoán vị trí của nó. Phần này sẽ giải thích cách tạo hệ thống dựa trên input từ người dùng, bao gồm hình ảnh hoặc hội thoại, rồi trích xuất vị trí và các dữ liệu đặc biệt liên quan đến mục đích của nó. Ý tưởng ở đây là thu thập dữ liệu từ người dùng, sau đó sử dụng AI để tìm ra dữ liệu địa lý tương ứng từ ảnh hoặc hội thoại.

<iframe width="560" height="315" src="https://www.youtube.com/embed/vu0jI6rm8go?si=OekTXKuHnseLaI_3&amp;start=2316" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

**41:21** - Sử dụng hệ thống prompt để tạo JSON

Tôi đã nhờ bên phía Cloack tạo giúp một prompt system. Quy trình này sẽ lặp lại nhiều lần để đảm bảo độ chính xác. Sau đó, tôi sao chép prompt và áp dụng lên các nền tảng như OpenAI để tiếp tục. Tôi chọn định dạng trả về là JSON và tiến hành với một bức ảnh. Mục tiêu là để AI đoán được vị trí từ bức ảnh và tạo ra một JSON object chứa các thông tin như liên kết Google Maps.

**42:26** - Thử nghiệm với ảnh văn phòng

Chúng ta sẽ thử sử dụng một bức ảnh văn phòng để kiểm tra xem AI có thể đoán được vị trí không. Sau khi tải ảnh lên, tôi định dạng lại output và hy vọng nó sẽ trả về kết quả chính xác cùng với liên kết Google Maps. Trong trường hợp này, kết quả có vẻ đúng khi nó xác định tòa nhà trong ảnh.

**43:21** - So sánh kết quả và suy luận vị trí

Tôi có thể so sánh JSON object được tạo ra và suy luận vị trí của bức ảnh này. AI đã phân tích hình ảnh và đưa ra vị trí chính xác từ các yếu tố hình ảnh trong bức ảnh đó. Đây là một cách sử dụng Cloack để xây dựng hệ thống map thông qua JSON, nhưng có thể mở rộng để output thêm các định dạng như SQL hoặc GraphQL.

**44:18** - Tối ưu hóa hệ thống

Phương pháp này giúp tôi dễ dàng định hướng cho AI và tạo ra prompt system một cách nhanh chóng. Mục tiêu của tôi là yêu cầu AI cung cấp vị trí dựa trên hình ảnh, nhưng kết quả đôi khi có thể không chính xác hoàn toàn nếu AI không có đủ dữ liệu tham khảo. Vì vậy, có thể cần phải chỉnh sửa lại prompt hoặc dùng các hình ảnh khác để thử nghiệm.

**44:57** - Cải thiện accuracy của AI

Khi thử các hình ảnh khác, tôi nhận ra rằng AI có thể gặp khó khăn trong việc xác định vị trí từ một số hình ảnh nhất định. Việc tối ưu hóa prompt system để AI hiểu đúng mục tiêu và trả về kết quả mong muốn là rất quan trọng. Chúng ta có thể cải thiện bằng cách cung cấp thông tin chi tiết hơn trong input hoặc cấu trúc lại cách AI hiểu dữ liệu đầu vào.

**45:53** - Tạo prompt từ hình ảnh hoặc hội thoại

Một ý tưởng khác là sử dụng hội thoại làm input thay vì hình ảnh. Chúng ta có thể yêu cầu AI xác định vị trí hoặc dữ liệu liên quan từ các hội thoại đó. Trong trường hợp này, AI sẽ phải dựa vào ngữ cảnh và thông tin từ cuộc trò chuyện để đưa ra kết quả. Tuy nhiên, điều này yêu cầu sự tùy chỉnh nhiều hơn cho prompt system.

**46:50** - Độ chính xác khi sử dụng Cloack

Tôi nhận thấy rằng độ chính xác của Cloack trong việc xử lý input và trả về output liên quan đến không gian và thời gian là khá cao, gần 100%. Điều này cho thấy việc định nghĩa rõ ràng input, output và mục tiêu của hệ thống là rất quan trọng để AI hoạt động hiệu quả.

**47:40** - Sử dụng prompt system cho các ví dụ khác

Ngoài việc sử dụng để đoán vị trí, prompt system có thể được áp dụng vào các bài toán khác như chuyển đổi query ngôn ngữ tự nhiên thành query ngôn ngữ lập trình. Đây là một ứng dụng khác của prompt system mà tôi sẽ demo tiếp theo, để AI có thể hiểu và xử lý các query một cách chính xác hơn.

**48:27** - Ví dụ về việc sử dụng prompt system để tạo các prompt khác

Một ví dụ khác là sử dụng prompt system để tạo ra các prompt mới, cải tiến từ các prompt cũ. Ví dụ, tôi có thể lấy một prompt hiện tại và yêu cầu AI cải thiện nó, tạo ra một output tốt hơn như chuyển từ output dạng text thành output dạng JSON. Điều này có thể hữu ích trong việc suy nghĩ hệ thống theo cách mà AI có thể xử lý tốt hơn.

**50:33** - Cách AI xử lý dữ liệu từ prompt

Tôi đã thử nghiệm với một số prompt cũ và yêu cầu AI chuyển đổi nó thành prompt mới với cấu trúc tốt hơn. Trong quá trình này, AI có thể dựa vào dữ liệu từ các prompt trước để đưa ra một prompt phù hợp với mục tiêu mới. Điều này giúp chúng ta tạo ra các prompt hiệu quả hơn mà không cần phải viết lại từ đầu.

**52:12** - Sử dụng AI để tối ưu hóa chatbot

Ví dụ, tôi có thể yêu cầu AI cải thiện prompt của một chatbot hiện tại để nó có thể tóm tắt thông tin tốt hơn. AI sẽ dựa trên prompt ban đầu và các output trước đó để tạo ra một prompt mới phù hợp với mục đích tối ưu hóa chatbot.

**53:59** - Tự động hóa quy trình tạo prompt system

So với việc tạo prompt thủ công, sử dụng AI để tự động hóa quy trình này sẽ nhanh hơn và tiết kiệm thời gian hơn. Tuy nhiên, có thể vẫn cần phải chỉnh sửa thủ công để đảm bảo prompt system hoạt động đúng mục tiêu, đặc biệt là khi AI chưa được huấn luyện đầy đủ với các dữ liệu liên quan.

**54:42** - So sánh dữ liệu và độ hiểu biết của AI

Tôi có thể so sánh dữ liệu mà AI trả về với kết quả mong đợi để đánh giá độ chính xác của prompt system. Nếu AI không hiểu đúng ngữ cảnh hoặc mục tiêu, có thể cần phải cung cấp thêm ví dụ hoặc điều chỉnh template để đạt được kết quả chính xác hơn.

**55:37** - Sử dụng AI để giải thích quy trình

Một ứng dụng khác là sử dụng AI để giải thích các bước trong quy trình phát triển. Ví dụ, AI có thể đọc mã nguồn hiện có và tạo ra một system prompt để giải thích quy trình làm việc hoặc các bước cần thiết để thực hiện một tính năng mới.

**56:23** - Tự động hóa việc tạo system prompt cho các tính năng mới

Nếu tôi muốn thêm một tính năng mới vào một phần mềm hiện có, tôi có thể sử dụng AI để tạo một prompt system. AI có thể phân tích mã nguồn hiện có và gợi ý các thay đổi cần thiết để tích hợp tính năng mới. Điều này giúp tiết kiệm thời gian và đảm bảo rằng tính năng mới phù hợp với kiến trúc hệ thống.

**57:04** - Áp dụng AI cho việc tích hợp giữa các hệ thống

Ví dụ, khi chuyển từ một hệ thống EVM sang một hệ thống khác có cấu trúc tương tự, tôi có thể sử dụng AI để tự động hóa quy trình tích hợp, từ đó giúp quá trình phát triển diễn ra nhanh hơn và hiệu quả hơn.

**57:49** - Tạo prompt system cho việc phát triển tính năng mới

Tôi có thể yêu cầu AI tạo ra một system prompt để giải thích các bước cần thiết trong việc phát triển một tính năng mới, từ việc cập nhật file, interface đến việc tạo ra các component map hoặc package map.

**58:32** - Ví dụ về việc tạo system prompt

Ví dụ, tôi có thể yêu cầu AI tạo một prompt system để giải thích cách thực hiện các bước cần thiết trong việc phát triển một tính năng mới. AI sẽ tạo ra một system prompt dựa trên các thông tin đầu vào và cung cấp các hướng dẫn chi tiết về các thay đổi cần thực hiện trong mã nguồn.

**59:19** - Kết luận

Quy trình sử dụng AI để tạo system prompt là một bước tiến lớn trong việc tự động hóa phát triển phần mềm. Tuy nhiên, cần phải có sự cân nhắc về cách huấn luyện AI để đảm bảo rằng nó có thể hiểu đúng ngữ cảnh và đưa ra các gợi ý phù hợp cho việc phát triển hệ thống.

**01:00:18** Có ai hỏi gì thêm không? Chắc để tôi show cho anh em xem bản chất của một cái "System BOM" (Bill of Materials) và nó như thế nào thì nó mới được gọi là tốt. Thì một BOM tốt sẽ cần có những yếu tố gì, thành phần nào? Ví dụ như, theo kinh nghiệm thì nhiều khi nên "fill SH" (tạo Skeleton Structure) trước, rồi điền vài example cho dễ kiểm tra. Mọi người thấy đúng không? Thực tế thì để chuẩn bị một system prop cho enterprise, cần dựa trên dữ liệu rõ ràng để có bằng chứng giải thích cho client hiểu. Sau đó, mình có thể nhờ AI (Artificial Intelligence) để hỗ trợ tạo prop, rồi mình kiểm tra, test xem prop đó có ổn không. Nếu ổn thì mình mới đưa vào quy trình và cho auto luôn.

**01:01:04** Thế là sẽ hình dung ra một mô hình (model) đánh giá từ góc nhìn của mình. Nó sẽ có chức năng so sánh và đánh giá rằng: "À, cái này đúng rồi, cái này phù hợp", chẳng hạn có tên gọi là "Evaluator". Câu hỏi của anh là làm sao mình biết cái System BOM này có đủ tiêu chuẩn không?

**01:01:43** Ví dụ như em tạo một cái description và từ đó ra một "System Y", đúng không? Thì tiêu chí đánh giá sẽ là gì? Làm sao biết được nó hợp lý hay không?

**01:02:28** Nếu muốn đánh giá về "semantic" (ngữ nghĩa), thì AI sẽ phải đánh giá về cấu trúc dữ liệu (JSON), và kiểm tra tính chính xác của dữ liệu đó. Nếu cần kiểm tra về cấu trúc (structure) của JSON, có thể dùng một công cụ kiểu "Lexical Compiler", để kiểm tra format có đúng không, prefix có chuẩn không. Có những công cụ để kiểm tra thêm, ngoài ngữ nghĩa thì còn phải đảm bảo dữ liệu trả về đầy đủ, chính xác. Ví dụ, nó trả lại dữ liệu nhưng chỉ đạt 80% hoặc 90%, mình có thể lập trình thêm một số bước để kiểm tra độ bao phủ của output bằng các phương pháp tìm kiếm từ khóa (Keyword Search).

**01:03:45** Cuối cùng, mình so sánh output của AI với các tiêu chuẩn mà mình mong muốn như về cấu trúc, ngữ nghĩa hay định dạng. Nếu đạt yêu cầu, mình có thể tiếp tục sử dụng. Thành có hỏi làm sao để đánh giá semantic mà lại có thể chuẩn hóa (standardize) cách đo lường, đúng không?

**01:04:31** Mình sẽ verify phần output chứ không chỉ xác nhận từng bước của system prop. Kiểu như mình xem qua rồi thấy ok thì mới chốt là cái BOM đó chuẩn.

**01:06:26** Em xin điểm qua cái tuần này nha. Bài đầu tiên có tín hiệu khá khả quan là thằng Igo vừa tuần rồi đã ra bản mới, hỗ trợ Go 1.23 và có thêm các tính năng mới như `Range over function`. Đây là một compiler dành cho WebAssembly hoặc các microcontroller kiểu embedded. Rồi một tool khác nữa là `xcv`, một vector extension cho C, trước đây phát triển bởi cá nhân nhưng giờ thuộc Mozilla.

<iframe width="560" height="315" src="https://www.youtube.com/embed/vu0jI6rm8go?si=ouW-MLqxz8PQnYQL&amp;start=3978" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

**01:07:54** Tiếp theo là tool permify, một authorization service lấy cảm hứng từ Google Z bar. Nó claim rằng abstract hóa hoàn toàn logic authorization ra khỏi codebase để dễ test và quản lý, đồng thời tương thích với các phương pháp như role-based, relation-based, và attribute-based authorization. Nó cũng có khả năng tích hợp với các vendor khác dễ dàng.

**01:09:52** Ngoài ra, em vừa boost thêm một số content liên quan đến Go enterprise. Nội dung đang được cập nhật dần và sẽ giải thích lý do Java được chọn cho enterprise, và vì sao Go có thể thay thế được Java trong nhiều trường hợp enterprise hiện tại.

**01:10:33** Mọi người cũng có thể input thêm vào channel, hiện tại chủ yếu đang cố gắng map các tiêu chí của Java và Go, đặc biệt là trong bối cảnh enterprise. Cũng sẽ cố gắng tổng hợp thêm các nguồn từ anh em để trả lời những câu hỏi như tại sao Go lại đang dần trở thành một lựa chọn thay thế cho Java trong các hệ thống lớn.

**01:11:43** Phần này hướng đến việc làm rõ lý do Go được các enterprise chọn, cùng với các case study về những công ty đang chuyển từ Ruby qua Go. Dự kiến sẽ có nhiều ví dụ cụ thể để chứng minh tính khả thi và tính ổn định của Go trong bối cảnh enterprise.

**01:12:23** Dự kiến sẽ có thêm nhiều case study từ các công ty lớn đã chuyển qua Go và lý do đằng sau sự thay đổi này, đặc biệt là khi so sánh về chi phí và hiệu quả giữa Java và Go trong các ứng dụng enterprise hiện đại.

**01:14:23** Cuối cùng, tụi anh dự kiến sẽ phát triển cộng đồng Go lớn mạnh hơn bằng cách thu thập thêm những case study cụ thể và có thể giúp các công ty khác dễ dàng đưa ra quyết định chuyển sang Go.

**01:15:11** Bài này về chuyện cổ vũ các bạn làm những tool nhỏ nhưng chất lượng, có thể phát triển để thành sản phẩm thương mại hóa. Trong tương lai, xu hướng solo developer sẽ càng phát triển mạnh hơn. Anh muốn hỗ trợ các bạn thông qua việc setup một lượng ICY để khuyến khích những sản phẩm sáng tạo, như Tuấn đang làm. Các bạn hoàn toàn có thể phát triển những tool nhỏ và thêm vài tính năng để hoàn thiện, từ đó tạo ra sản phẩm có thể kiếm tiền.

**01:16:21** Cộng đồng Go cũng đang quay lại với các hoạt động mới. Mình sẽ triển khai mô hình “contribution and earn” như team mình đang làm. Huy sẽ phụ trách setup hệ thống này. Ngoài ra, mình cũng sẽ làm một đợt giveaway cho áo Go cũ và mới để thu hút thêm người tham gia cộng đồng. Đây là những bước để thúc đẩy phong trào lập trình Go trong cộng đồng.

**01:17:01** Còn một phần nữa liên quan đến việc giảm chi phí sản xuất phần mềm. Hiện tại, các công nghệ EOM đang là trung tâm của việc này, như Tom đã demo cho team. Nếu chúng ta có thể nắm bắt kiến thức về những công nghệ này thì sẽ giúp đẩy nhanh quá trình code, xây dựng và phát hành sản phẩm. Điều này rất quan trọng với thời đại hiện nay.

**01:17:46** Các chủ đề tiếp theo trong tháng chắc sẽ được Thành sắp xếp. Anh muốn tuyên dương team Debo vì vẫn đang theo dõi và hỗ trợ quá trình deploy dự án. Mong rằng các anh em test và chia sẻ trải nghiệm của mình, nhất là với những máy yếu để xem Debox có phù hợp không.

**01:18:29** Còn về những phần khác, Tom đang tiếp tục pick up các phần về LLM và chia sẻ với toàn bộ team. Phần của Huy nhỏ và Tuấn cũng rất quan trọng, cả hai đang xử lý nhiều công việc nặng, nhưng kết quả vẫn khả quan.

**01:20:51** Nếu trong quá trình xem có bài viết nào trên kênh tech mà mọi người muốn làm một buổi talk nhỏ, thì cứ đăng ký nhé, càng hoan nghênh. Đăng ký với Thành hay ping anh cũng được. Mình sẽ thoải mái trao đổi cùng mọi người.

---

**00:00** - Meeting begins

Ok, is everyone here? Thành, where do you want to start today? Is anyone missing? It seems like Thành is having some audio issues, can't hear clearly. Alright, looks like everyone is here, so let's begin.

**11:46** - August activity summary

Hello everyone, welcome back to this week's OGIF. Today we'll also combine some reports on August activities. Basically, there's nothing too new, except after three months of trial running the ICY mechanism, we see that knowledge-sharing activities have been increasing as planned, even surpassing the set goals. This is a very positive sign, and it's what I find most valuable at the moment.

**12:39** - Results from applying ICY

The clearest result we've seen from applying ICY is the opportunity for learning and discussion every Friday. Everyone has a chance to bring up issues and discuss them together, learning from each other. This is the clearest result we've gained from this August. In the last meeting, someone from the team asked about our team's token dfg, and today we'll discuss this further.

**13:21** - Introduction to Token dfg

Specifically, in the team's plan from the beginning of the year, we aimed to build a strong "internet brand" that everyone can be proud to be part of. This dfg token will function similarly to a stock, but exclusively internal. To obtain this token before 2020, people had to view it as an internal employee ownership program (EOP). Currently, we are transitioning the mechanism for recording contributions and preparing for earning this token through team activities.

**14:10** - dfg Token development plan

Initially, the dfg token operated like a private stock. But later, we announced that people could earn this token through contributing to team activities. While the team is proceeding with planned activities, we're also preparing so that all members can earn this token. Currently, to earn this token, everyone needs to have ICY coins and participate in the activities listed in the earn ICY channel.

**14:51** - dfg Token and contribution recording process

Before 2020, obtaining the dfg token was considered a form of internal stock or ESOP. However, we've now set up a contribution recording process for the team. This allows members to earn the dfg token through contributions to team activities. The next step is that everyone will need ICY coins to participate in the activities listed in the earn IC channel.

**15:35** - Team contributions

People can earn ICY by participating in activities like research, knowledge sharing, or directly joining projects. These contributions will be recorded and converted into ICY. Activities like cashing out to help others can also be seen as a way to accumulate ICY. Additionally, some members can use ICY through the salary advance mechanism.

**16:45** - Brand development

Recording contributions and owning dfg tokens will help us build the team’s brand more strongly. The team is establishing mechanisms to make it easier for everyone to contribute and own part of the team's token. These tokens can be used in internal activities and potentially extended outside through staking. This is an important step in developing the decentralized governance system (DFG).

**19:08** - AI market trends

In the past three months, AI-related topics have garnered increasing attention, with many AI applications being introduced and developed. Our team is also shifting in this direction, with activities like AI tool demos and discussions about the technological market shift. In September, the team will announce more official guides related to developing small AI projects, focusing on solving specific problems and optimizing workflows.

**21:13** - Impact of AI on software development costs

The cost of software development is steadily decreasing due to AI's development. Companies will no longer need to invest heavily in manual activities but instead look for people capable of effectively using AI. This shift will create a new generation of entrepreneurs who can leverage AI to build software products faster and more efficiently. Our team is also transitioning in this direction.

**22:33** - Official streams and open-source projects

In September, the team will launch small open-source projects focusing on solving specific problems through powerful tools. Those who participate in these projects and can turn them into complete products will be recognized and rewarded with IC. This is a new direction encouraging members to create sharp, small products that contribute to the team’s development.

**23:57** - Recruitment and layoffs

Although there have been some layoffs in the tech market, recruitment demand still exists, particularly among small and medium-sized companies experimenting with new technologies. Many large companies are still refining their human resources to adapt to this shift. AI continues to play an important role in optimizing costs and software development processes.

**25:41** - Team operations status

Some consulting projects have been paused due to market misalignment, resulting in reduced investment in certain resources. However, this presents an opportunity for our team to focus on more strategic projects and build valuable case studies. Currently, the team’s operations are running smoothly, and new AI projects will continue to roll out in the near future.

**26:20** - OGIF presentation

We have three presentations today. The first is about Lego, and the next is about MC with aspects related to enterprise. The third one is a market report summary concerning AI, which we’ve already discussed. The final presentation is Tom’s sharing about the process of handling a prompt using AI and how to create a more effective prompt for information processing.

**27:05** - In-depth analysis of a developer's mindset

Last time, Minh Cloud shared about data processing from a regular user's perspective. However, today we’ll dive deeper from a developer's perspective, especially regarding the mindset of developers during system development.

**27:51** - Quang Lê and the team’s portfolio

Over the past week, Quang Lê has prepared a summary report on the team's portfolio, including information gathered from various projects. We’ll review these projects to get an overview of what has been done and what needs improvement.

**30:03** - Data aggregation and report publication

During the aggregation process, Quang used EOM and other tools to collect data from multiple sources. The information was then exported into PDF files for easy sharing and storage. Everything from blockchain to other projects has been compiled.

**31:25** - Using AI for report compilation

Quan utilized AI tools like GPT and Cloud to process PDF documents and generate detailed summaries for each project. After scanning the PDFs, the AI extracted information and created comprehensive summary reports in the form of case studies.

**35:11** - Automating the report creation process

By using tools like Cloud and GPT, Quan automated much of the report creation process. This saved time and ensured that the information was collected and processed accurately. Automation also made it easy to update the information whenever necessary.

**37:31** - Presenting case studies

The case studies from various projects were processed by AI and turned into complete reports. This process helped us easily capture the skills developed through each project and identify the next steps that need to be taken.

**38:13** - Data processing and information aggregation

Quan spent approximately two weeks compiling and generating reports for over ten projects. This method is useful for tracking the team's progress and evaluating the skills developed across different projects.

**39:15** - Prompt Engineering

Tom will explain prompt engineering and how to create prompts to process information using AI. Previously, we did this manually, but now we will use AI to automate the process. Today's goal is to create a prompt that automates the process of extracting specific information from images or conversations.

**39:49** - Prompt for generating a JSON

The goal of this JSON relates to OSINT (Open Source Intelligence). I will use an image as input and employ AI to estimate its location. This section will explain how to build a system based on user input, including images or conversations, and then extract the location and specific data relevant to the task. The idea is to gather user data and use AI to find corresponding geographic data from the image or conversation.

**41:21** - Using the prompt system to generate JSON

I had Cloack create a prompt system for me. This process repeats several times to ensure accuracy. Then, I copied the prompt and applied it to platforms like OpenAI. I chose JSON as the output format and worked with an image. The goal is for AI to estimate the location from the image and generate a JSON object containing information such as a Google Maps link.

**42:26** - Experimenting with an office photo

We will try using an office photo to see if AI can estimate the location. After uploading the image, I reformatted the output and hope it will return an accurate result along with a Google Maps link. In this case, the result seems correct as it identified the building in the photo.

**43:21** - Comparing results and deducing the location

I can compare the generated JSON object and deduce the location of the image. The AI analyzed the image and accurately identified the location based on visual elements in the photo. This is a way of using Cloack to build a mapping system through JSON, but it can be expanded to output formats like SQL or GraphQL.

**44:18** - Optimizing the system

This method allows me to quickly guide the AI and create a prompt system. My goal is to have AI provide the location based on the image, but sometimes the results may not be entirely accurate if AI lacks enough reference data. Therefore, the prompt may need adjustments or other images used for testing.

**44:57** - Improving AI accuracy

When testing with other images, I noticed that AI may struggle to identify the location in certain images. Optimizing the prompt system so that AI correctly understands the goal and returns the desired result is crucial. We can improve this by providing more detailed input information or restructuring how AI interprets the data.

**45:53** - Creating prompts from images or conversations

Another idea is to use conversations as input instead of images. We could ask AI to determine the location or relevant data from those conversations. In this case, AI would need to rely on the context and information from the conversation to produce the result. However, this requires more customization for the prompt system.

**46:50** - Accuracy when using Cloack

I found that Cloack’s accuracy in processing input and returning spatial and temporal output is quite high, nearly 100%. This demonstrates the importance of clearly defining the input, output, and goal for the system to make AI work efficiently.

**47:40** - Using the prompt system for other examples

Beyond guessing locations, the prompt system can be applied to other problems, such as converting natural language queries into programming language queries. This is another application of the prompt system that I will demo next, allowing AI to understand and process queries more accurately.

**48:27** - Example of using the prompt system to create other prompts

Another example is using the prompt system to generate new prompts, improving on existing ones. For instance, I can take a current prompt and ask AI to enhance it, creating better output, such as converting from text output to JSON output. This can be helpful in thinking about the system in a way that AI can process better.

**50:33** - How AI processes data from prompts

I experimented with some old prompts and asked AI to transform them into new prompts with better structure. During this process, AI could rely on data from previous prompts to produce one that fits the new goal. This helps us create more effective prompts without having to rewrite them from scratch.

**52:12** - Using AI to optimize chatbots

For example, I could ask AI to improve a chatbot's prompt so it can summarize information better. AI will base the new prompt on the original one and previous outputs to create a new prompt tailored to optimizing the chatbot.

**53:59** - Automating the prompt system creation process

Compared to manually creating prompts, using AI to automate this process is faster and more time-efficient. However, manual adjustments may still be necessary to ensure that the prompt system works toward the intended goal, especially when AI has not been fully trained with the relevant data.

**54:42** - Comparing data and AI's understanding

I can compare the data AI returns with the expected results to evaluate the prompt system's accuracy. If AI doesn't understand the context or goal correctly, we may need to provide more examples or adjust the template to achieve more accurate results.

**55:37** - Using AI to explain processes

Another application is using AI to explain the steps in a development process. For example, AI can read existing source code and create a system prompt to explain the workflow or the necessary steps to implement a new feature.

**56:23** - Automating system prompt creation for new features

If I want to add a new feature to existing software, I can use AI to create a prompt system. AI can analyze the existing code and suggest necessary changes to integrate the new feature. This saves time and ensures that the new feature fits the system architecture.

**57:04** - Applying AI for system integration

For example, when migrating from one EVM-based system to another with a similar structure, I can use AI to automate the integration process, speeding up development and making it more efficient.

**57:49** - Creating a prompt system for feature development

I can ask AI to create a system prompt to explain the steps necessary for developing a new feature, from updating files and interfaces to creating component maps or package maps.

**58:32** - Example of system prompt creation

For example, I can ask AI to create a prompt system explaining how to perform the necessary steps for developing a new feature. AI will generate a system prompt based on the input information and provide detailed instructions for changes to be made in the source code.

**59:19** - Conclusion

The process of using AI to create system prompts is a significant step forward in automating software development. However, careful consideration is required when training AI to ensure it understands the context and provides suitable suggestions for system development.

**01:00:18** Does anyone have any additional questions? Let me show you the essence of a "System BOM" (Bill of Materials) and what makes a good one. A good BOM needs certain elements and components. For example, based on my experience, it’s often good to "fill SH" (create a Skeleton Structure) first, then add a few examples to make it easier to verify. Does that sound right? In practice, preparing a system prop for enterprise requires clear data to provide evidence that explains it to the client. Afterward, we can ask AI (Artificial Intelligence) to help create the prop, then we test it to see if it’s solid. If it’s good, we integrate it into the process and automate it.

**01:01:04** So, we can envision a model from our perspective. It will have a function that compares and evaluates, saying, "Ah, this is correct, this is appropriate," which we might call an "Evaluator." The question is, how do we know if the System BOM meets the standard?

**01:01:43** For example, you create a description, and from that, you get a "System Y," right? So what are the evaluation criteria? How do we know if it's reasonable or not?

**01:02:28** If you want to evaluate the "semantics," then AI will have to assess the data structure (JSON) and check the accuracy of that data. If you need to check the structure of the JSON, you can use a tool like a "Lexical Compiler" to verify if the format is correct, the prefixes are proper, etc. There are additional tools to ensure that beyond semantics, the data returned is complete and accurate. For instance, if it returns data that's only 80% or 90% accurate, you could program additional steps to check the output coverage using keyword search methods.

**01:03:45** Finally, we compare AI's output to the standards we expect, whether for structure, semantics, or format. If it meets the requirements, we continue using it. Thành asked how we can evaluate the semantics while standardizing the measurement method, correct?

**01:04:31** We’ll verify the output rather than just confirming each step of the system prop. It’s like reviewing it and, once we see it’s okay, then we can finalize that the BOM is standard.

**01:06:26** Let me summarize this week’s highlights. The first notable point is that Igo released a new version last week, supporting Go 1.23 and adding new features like `Range over function`. This is a compiler for WebAssembly or embedded microcontroller types. Another tool is `xcv`, a vector extension for C, which was previously developed by an individual but now belongs to Mozilla.

**01:07:54** Next is the tool Permify, an authorization service inspired by Google Z bar. It claims to completely abstract authorization logic out of the codebase, making it easier to test and manage, while also being compatible with methods like role-based, relation-based, and attribute-based authorization. It also integrates easily with other vendors.

**01:09:52** Additionally, I just boosted some content related to Go enterprise. The content is being updated gradually and will explain why Java was chosen for enterprise and why Go can replace Java in many current enterprise cases.

**01:10:33** Everyone can also input into the channel; right now, we're mainly trying to map the criteria between Java and Go, especially in the enterprise context. We’ll also try to compile additional sources from the team to answer questions like why Go is increasingly becoming a replacement for Java in large systems.

**01:11:43** This section aims to clarify why Go is being chosen by enterprises, along with case studies of companies transitioning from Ruby to Go. More examples will be provided to demonstrate the feasibility and stability of Go in enterprise applications.

**01:12:23** We plan to add more case studies from large companies that have switched to Go and the reasons behind this change, particularly when comparing costs and efficiency between Java and Go in modern enterprise applications.

**01:14:23** Lastly, we aim to grow the Go community by gathering specific case studies that can help other companies easily decide to transition to Go.

**01:15:11** This talk is about encouraging people to create small but quality tools that can be developed into commercial products. In the future, the trend of solo developers will grow even stronger. I want to support these efforts by setting up an amount of ICY to encourage creative products, like what Tuấn is working on. You can develop small tools, add some features to perfect them, and create products that can generate revenue.

**01:16:21** The Go community is also reviving with new activities. We will implement the "contribution and earn" model, like what our team is doing. Huy will be in charge of setting up this system. Additionally, we’ll conduct a giveaway for old and new Go shirts to attract more participants to the community. These are steps to promote Go programming within the community.

**01:17:01** One more point related to reducing software production costs: currently, EOM technologies are at the center of this, as Tom has demonstrated to the team. If we can grasp the knowledge of these technologies, it will help accelerate the coding, building, and product release processes. This is very important in today’s age.

**01:17:46** The upcoming topics for the month will likely be arranged by Thành. I want to comment the team for continuing to monitor and support the project deployment process. I hope everyone tests and shares their experiences, especially those with low-powered machines, to see if Devbox is suitable.

**01:18:29** As for other parts, Tô is continuing to pick up sections about AMOM and sharing them with the whole team. Huy and Tuấn’s parts are also very important, both handling heavy workloads, but the results are still promising.

**01:20:51** If there’s an article on the tech channel that anyone wants to do a small talk about, feel free to sign up, you're more than welcome. Register with Thành or ping me. We’ll be happy to discuss everything with everyone.
